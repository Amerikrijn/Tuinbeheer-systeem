#!/usr/bin/env ts-node

import { Command } from 'commander'
import { AIPipeline } from './pipeline'
import { PipelineConfig } from './types'
import * as fs from 'fs'
import * as path from 'path'
import chalk from 'chalk'

const program = new Command()

program
  .name('ai-pipeline')
  .description('AI-Powered Pipeline for Testing, Orchestration, and Code Fixing')
  .version('2.0.0')

program
  .command('run')
  .description('Run the AI pipeline')
  .option('-t, --target <path>', 'Target directory to analyze', './src')
  .option('-i, --iterations <number>', 'Maximum iterations', '10')
  .option('-q, --quality <number>', 'Quality threshold (0-100)', '90')
  .option('-o, --output <path>', 'Output directory', './ai-pipeline-results')
  .option('--auto-apply', 'Automatically apply fixes', false)
  .option('--git-integration', 'Enable Git integration', false)
  .option('--config <path>', 'Configuration file path')
  .option('--ci-mode', 'Run in CI mode without AI analysis', false)
  .option('--pr-review', 'Enable AI code review for PRs', false)
  .option('--github-token <token>', 'GitHub token for PR integration')
  .option('--repo <repo>', 'Repository name (owner/repo)')
  .option('--pr-number <number>', 'Pull request number')
  .action(async (options) => {
    try {
      console.log(chalk.blue('üöÄ AI Pipeline v2.0 Starting...'))
      console.log('')

      // Load configuration
      const config = await loadConfiguration(options.config)
      
      // Override config with CLI options
      config.maxIterations = parseInt(options.iterations)
      config.qualityThreshold = parseInt(options.quality)
      config.outputPath = options.output
      config.autoApply = options.autoApply
      config.gitIntegration = options.gitIntegration

      // Check if running in CI mode
      if (options.ciMode) {
        console.log(chalk.yellow('üîß Running in CI mode - skipping AI analysis'))
        console.log(chalk.blue(`üìÅ Target path: ${options.target}`))
        console.log(chalk.blue(`üìÅ Output path: ${options.output}`))
        console.log(chalk.blue(`üìÅ Current working directory: ${process.cwd()}`))
        
        // Check if target path exists
        try {
          const fs = require('fs')
          const path = require('path')
          const targetPath = path.resolve(options.target)
          console.log(chalk.blue(`üìÅ Resolved target path: ${targetPath}`))
          
          if (fs.existsSync(targetPath)) {
            console.log(chalk.green(`‚úÖ Target path exists`))
            if (fs.statSync(targetPath).isDirectory()) {
              const files = fs.readdirSync(targetPath)
              console.log(chalk.blue(`üìÅ Found ${files.length} items in target directory`))
              const tsFiles = files.filter((f: string) => f.endsWith('.ts') || f.endsWith('.tsx'))
              console.log(chalk.blue(`üìÅ Found ${tsFiles.length} TypeScript files`))
            }
          } else {
            console.log(chalk.red(`‚ùå Target path does not exist`))
          }
        } catch (error) {
          console.log(chalk.red(`‚ùå Error checking target path: ${error}`))
        }
        
        // Create basic validation results
        const results = {
          success: true,
          iterations: 1,
          finalQualityScore: 85, // Default good score for CI
          issuesFound: 0,
          issuesFixed: 0,
          testsGenerated: 0,
          executionTime: Date.now(),
          errors: [],
          timestamp: new Date(),
          mode: 'ci',
          aiProvider: 'ci-mode',
          targetPath: options.target,
          allIssues: [],
          allFixes: [],
          allTests: []
        }
        
        // Save results
        const outputDir = path.resolve(options.output)
        console.log(chalk.blue(`üìÅ Creating output directory: ${outputDir}`))
        
        if (!fs.existsSync(outputDir)) {
          fs.mkdirSync(outputDir, { recursive: true })
          console.log(chalk.green(`‚úÖ Created output directory`))
        }
        
        const outputFile = path.join(outputDir, 'pipeline-results.json')
        console.log(chalk.blue(`üìÅ Writing results to: ${outputFile}`))
        
        fs.writeFileSync(outputFile, JSON.stringify(results, null, 2))
        console.log(chalk.green(`‚úÖ Results saved successfully`))
        
        // Verify the file was created
        if (fs.existsSync(outputFile)) {
          const stats = fs.statSync(outputFile)
          console.log(chalk.green(`‚úÖ Output file exists, size: ${stats.size} bytes`))
        } else {
          console.log(chalk.red(`‚ùå Output file was not created`))
        }
        
        console.log(chalk.green('‚úÖ CI mode completed successfully'))
        console.log(chalk.blue(`üìÅ Results saved to: ${options.output}`))
        return
      }

      // Validate OpenAI API key (only for non-CI mode)
      const openaiApiKey: string = process.env.OPENAI_API_KEY || ''
      if (!openaiApiKey) {
        throw new Error('OPENAI_API_KEY environment variable is required for AI analysis mode')
      }

      console.log(chalk.green('‚úÖ OpenAI API key found'))
      console.log(chalk.blue(`üéØ Quality threshold: ${config.qualityThreshold}%`))
      console.log(chalk.blue(`üîÑ Max iterations: ${config.maxIterations}`))
      console.log(chalk.blue(`üìÅ Target: ${options.target}`))
      console.log('')

      // Create and run pipeline
      const pipeline = new AIPipeline(config, openaiApiKey)
      const results = await pipeline.run(options.target)

      // Display results
      displayResults(results)

      // Save results
      await saveResults(results, options.output)

    } catch (error) {
      console.error(chalk.red('‚ùå Pipeline failed:'), error)
      process.exit(1)
    }
  })

program
  .command('config')
  .description('Manage pipeline configuration')
  .option('--init', 'Initialize default configuration')
  .option('--show', 'Show current configuration')
  .option('--set <key=value>', 'Set configuration value')
  .action(async (options) => {
    try {
      if (options.init) {
        await initializeConfiguration()
      } else if (options.show) {
        await showConfiguration()
      } else if (options.set) {
        await setConfiguration(options.set)
      } else {
        console.log(chalk.yellow('Use --init, --show, or --set to manage configuration'))
      }
    } catch (error) {
      console.error(chalk.red('‚ùå Configuration failed:'), error)
      process.exit(1)
    }
  })

program
  .command('agents')
  .description('Manage AI agents')
  .option('--list', 'List available agents')
  .option('--status', 'Check agent status')
  .action(async (options) => {
    try {
      if (options.list) {
        await listAgents()
      } else if (options.status) {
        await checkAgentStatus()
      } else {
        console.log(chalk.yellow('Use --list or --status to manage agents'))
      }
    } catch (error) {
      console.error(chalk.red('‚ùå Agent management failed:'), error)
      process.exit(1)
    }
  })

async function loadConfiguration(configPath?: string): Promise<PipelineConfig> {
  const defaultConfig: PipelineConfig = {
    agents: [
      {
        id: 'issue-collector',
        name: 'Issue Collector',
        description: 'Finds code issues and problems',
        provider: {
          name: 'OpenAI GPT-4',
          type: 'openai',
          config: {},
          isAvailable: true
        },
        enabled: true,
        config: {}
      },
      {
        id: 'test-generator',
        name: 'Test Generator',
        description: 'Generates test cases for issues',
        provider: {
          name: 'Anthropic Claude',
          type: 'anthropic',
          config: {},
          isAvailable: false
        },
        enabled: true,
        config: {}
      },
      {
        id: 'code-fixer',
        name: 'Code Fixer',
        description: 'Fixes identified code issues',
        provider: {
          name: 'OpenAI GPT-4',
          type: 'openai',
          config: {},
          isAvailable: true
        },
        enabled: true,
        config: {}
      },
      {
        id: 'quality-validator',
        name: 'Quality Validator',
        description: 'Validates code quality improvements',
        provider: {
          name: 'OpenAI GPT-4',
          type: 'openai',
          config: {},
          isAvailable: true
        },
        enabled: true,
        config: {}
      }
    ],
    maxIterations: 10,
    qualityThreshold: 90,
    autoApply: false,
    gitIntegration: false,
    outputPath: './ai-pipeline-results',
    qualityChecks: ['eslint'],
    logLevel: 'info'
  }

  if (configPath && fs.existsSync(configPath)) {
    try {
      const configContent = fs.readFileSync(configPath, 'utf-8')
      const userConfig = JSON.parse(configContent)
      return { ...defaultConfig, ...userConfig }
    } catch (error) {
      console.warn(chalk.yellow(`‚ö†Ô∏è Failed to load config from ${configPath}: ${error}`))
    }
  }

  return defaultConfig
}

function displayResults(results: any): void {
  console.log('')
  console.log(chalk.blue('üìä AI Pipeline Results'))
  console.log('‚îÄ'.repeat(50))
  
  if (results.success) {
    console.log(chalk.green(`‚úÖ Status: SUCCESS`))
    console.log(chalk.blue(`üéØ Quality Score: ${results.finalQualityScore}/100`))
    console.log(chalk.blue(`üîÑ Iterations: ${results.iterations}`))
    console.log(chalk.blue(`üîç Issues Found: ${results.issuesFound}`))
    console.log(chalk.blue(`üîß Issues Fixed: ${results.issuesFixed}`))
    console.log(chalk.blue(`üß™ Tests Generated: ${results.testsGenerated}`))
    console.log(chalk.blue(`‚è±Ô∏è Execution Time: ${(results.executionTime / 1000).toFixed(2)}s`))
    console.log(chalk.blue(`ü§ñ AI Provider: ${results.aiProvider}`))
    console.log(chalk.blue(`üîß Mode: ${results.mode}`))
  } else {
    console.log(chalk.red(`‚ùå Status: FAILED`))
    if (results.errors && results.errors.length > 0) {
      console.log(chalk.red(`‚ùå Errors:`))
      results.errors.forEach((error: string) => {
        console.log(chalk.red(`   - ${error}`))
      })
    }
  }
  
  console.log('')
}

async function saveResults(results: any, outputPath: string): Promise<void> {
  try {
    const outputDir = path.resolve(outputPath)
    if (!fs.existsSync(outputDir)) {
      fs.mkdirSync(outputDir, { recursive: true })
    }
    
    const outputFile = path.join(outputDir, 'pipeline-results.json')
    fs.writeFileSync(outputFile, JSON.stringify(results, null, 2))
    
    console.log(chalk.green(`‚úÖ Results saved to: ${outputFile}`))
  } catch (error) {
    console.error(chalk.red(`‚ùå Failed to save results: ${error}`))
  }
}

async function initializeConfiguration(): Promise<void> {
  const configPath = './ai-pipeline.config.json'
  const config = await loadConfiguration()
  
  fs.writeFileSync(configPath, JSON.stringify(config, null, 2))
  console.log(chalk.green(`‚úÖ Configuration initialized at: ${configPath}`))
}

async function showConfiguration(): Promise<void> {
  const config = await loadConfiguration()
  console.log(chalk.blue('üìã Current Configuration:'))
  console.log(JSON.stringify(config, null, 2))
}

async function setConfiguration(keyValue: string): Promise<void> {
  console.log(chalk.yellow('‚ö†Ô∏è Configuration setting not implemented yet'))
}

async function listAgents(): Promise<void> {
  const config = await loadConfiguration()
  console.log(chalk.blue('ü§ñ Available Agents:'))
  
  config.agents.forEach(agent => {
    const status = agent.enabled ? chalk.green('‚úÖ') : chalk.red('‚ùå')
    const provider = agent.provider.isAvailable ? chalk.green(agent.provider.name) : chalk.red(agent.provider.name)
    console.log(`${status} ${agent.name} (${agent.id}) - ${agent.description}`)
    console.log(`   Provider: ${provider}`)
  })
}

async function checkAgentStatus(): Promise<void> {
  console.log(chalk.yellow('‚ö†Ô∏è Agent status checking not implemented yet'))
}

program.parse()